{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please set env variable SPARK_VERSION\n"
     ]
    }
   ],
   "source": [
    "import src.sparkclient as scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/igor/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/igor/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/Users/igor/.local/share/virtualenvs/data-studio-exercise-python-sql-x46TW6ms/lib/python3.8/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "com.databricks#spark-xml_2.12 added as a dependency\n",
      "com.amazon.deequ#deequ added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-45ffaaa9-96a8-4254-873a-2bb3f87227ec;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.databricks#spark-xml_2.12;0.12.0 in central\n",
      "\tfound commons-io#commons-io;2.8.0 in central\n",
      "\tfound org.glassfish.jaxb#txw2;2.3.3 in central\n",
      "\tfound org.apache.ws.xmlschema#xmlschema-core;2.2.5 in central\n",
      "\tfound com.amazon.deequ#deequ;1.2.2-spark-3.0 in central\n",
      "\tfound org.scalanlp#breeze_2.12;0.13.2 in central\n",
      "\tfound org.scalanlp#breeze-macros_2.12;0.13.2 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.1 in central\n",
      "\tfound com.github.fommil.netlib#core;1.1.2 in central\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in central\n",
      "\tfound com.github.rwl#jtransforms;2.4.0 in central\n",
      "\tfound junit#junit;4.8.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.2 in central\n",
      "\tfound org.spire-math#spire_2.12;0.13.0 in central\n",
      "\tfound org.spire-math#spire-macros_2.12;0.13.0 in central\n",
      "\tfound org.typelevel#machinist_2.12;0.6.1 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.2 in central\n",
      "\tfound org.typelevel#macro-compat_2.12;1.1.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n",
      ":: resolution report :: resolve 1152ms :: artifacts dl 45ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazon.deequ#deequ;1.2.2-spark-3.0 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.2 from central in [default]\n",
      "\tcom.databricks#spark-xml_2.12;0.12.0 from central in [default]\n",
      "\tcom.github.fommil.netlib#core;1.1.2 from central in [default]\n",
      "\tcom.github.rwl#jtransforms;2.4.0 from central in [default]\n",
      "\tcommons-io#commons-io;2.8.0 from central in [default]\n",
      "\tjunit#junit;4.8.2 from central in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from central in [default]\n",
      "\torg.apache.ws.xmlschema#xmlschema-core;2.2.5 from central in [default]\n",
      "\torg.glassfish.jaxb#txw2;2.3.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.1 from central in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;0.13.2 from central in [default]\n",
      "\torg.scalanlp#breeze_2.12;0.13.2 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\torg.spire-math#spire-macros_2.12;0.13.0 from central in [default]\n",
      "\torg.spire-math#spire_2.12;0.13.0 from central in [default]\n",
      "\torg.typelevel#machinist_2.12;0.6.1 from central in [default]\n",
      "\torg.typelevel#macro-compat_2.12;1.1.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.scala-lang#scala-reflect;2.12.0 by [org.scala-lang#scala-reflect;2.12.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   20  |   0   |   0   |   1   ||   19  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-45ffaaa9-96a8-4254-873a-2bb3f87227ec\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 19 already retrieved (0kB/28ms)\n",
      "21/12/04 16:31:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = scl.SparkClient(\"XML_Import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AcceptedAnswerId: long (nullable = true)\n",
      " |-- AnswerCount: long (nullable = true)\n",
      " |-- Body: string (nullable = true)\n",
      " |-- ClosedDate: timestamp (nullable = true)\n",
      " |-- CommentCount: long (nullable = true)\n",
      " |-- CommunityOwnedDate: timestamp (nullable = true)\n",
      " |-- ContentLicense: string (nullable = true)\n",
      " |-- CreationDate: timestamp (nullable = true)\n",
      " |-- FavoriteCount: long (nullable = true)\n",
      " |-- Id: long (nullable = true)\n",
      " |-- LastActivityDate: timestamp (nullable = true)\n",
      " |-- LastEditDate: timestamp (nullable = true)\n",
      " |-- LastEditorDisplayName: string (nullable = true)\n",
      " |-- LastEditorUserId: long (nullable = true)\n",
      " |-- OwnerDisplayName: string (nullable = true)\n",
      " |-- OwnerUserId: long (nullable = true)\n",
      " |-- ParentId: long (nullable = true)\n",
      " |-- PostTypeId: long (nullable = true)\n",
      " |-- Score: long (nullable = true)\n",
      " |-- Tags: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- ViewCount: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts = sc.spark.read.parquet(\"uncommitted/posts.parquet\")\n",
    "posts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Count: long (nullable = true)\n",
      " |-- ExcerptPostId: long (nullable = true)\n",
      " |-- Id: long (nullable = true)\n",
      " |-- TagName: string (nullable = true)\n",
      " |-- WikiPostId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags = sc.spark.read.parquet(\"uncommitted/tags.parquet\")\n",
    "tags.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PostId: long (nullable = true)\n",
      " |-- TagId: long (nullable = true)\n",
      " |-- TagName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts_tags = sc.spark.read.parquet(\"uncommitted/posts_tags.parquet\")\n",
    "posts_tags.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Spark SQL\n",
    "Below is a sample SQL to find most popular tags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "posts.registerTempTable(\"p\")\n",
    "tags.registerTempTable(\"t\")\n",
    "posts_tags.registerTempTable(\"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "                           TagName  PostCount\n0                  neural-networks       2165\n1                 machine-learning       1908\n2           reinforcement-learning       1807\n3                    deep-learning       1627\n4    convolutional-neural-networks        998\n..                             ...        ...\n986           wake-sleep-algorithm          1\n987                 reward-hacking          1\n988             production-systems          1\n989                        p-value          1\n990                           rave          1\n\n[991 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TagName</th>\n      <th>PostCount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neural-networks</td>\n      <td>2165</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>machine-learning</td>\n      <td>1908</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>reinforcement-learning</td>\n      <td>1807</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>deep-learning</td>\n      <td>1627</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>convolutional-neural-networks</td>\n      <td>998</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>986</th>\n      <td>wake-sleep-algorithm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>987</th>\n      <td>reward-hacking</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>production-systems</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>p-value</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>990</th>\n      <td>rave</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>991 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.spark.sql(\"\"\"\n",
    "SELECT pt.TagName, COUNT(*) AS PostCount\n",
    "FROM p JOIN pt ON pt.PostId = p.Id\n",
    "GROUP BY pt.TagName\n",
    "ORDER BY PostCount DESC\n",
    "\"\"\").toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stop Spark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "sc.spark.stop()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}